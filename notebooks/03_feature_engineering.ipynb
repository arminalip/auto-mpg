{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Feature Engineering and Selection"]},{"cell_type":"markdown","metadata":{},"source":["Main steps:\n","- We only select numerical feature: we drop `name` and `company`\n","- We use `median` strategy for missing values in `horsepower` since it is tail heavy.\n","- We standardize numerical features. Not all algorithms need scaling to perform well. For example, linear regression (when not trained with gradient descent) and tree-based algorithms don't suffer from features not being on the same scale and centred around zero. We will, however, scale features in case we want to use algorithms other than the latter.\n","- We one-hot-encode `region` and drop the column corresponding to `Europe` to limit colinearity in the dataset."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"application/javascript":"\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_formatted_code = \"# use black formatter\\n%load_ext nb_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        nbb_cells[i].set_text(nbb_formatted_code);\n                        break;\n                    }\n                }\n            }, 500);\n            ","text/plain":"<IPython.core.display.Javascript object>"},"metadata":{},"output_type":"display_data"}],"source":"# use black formatter\n%load_ext nb_black"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"application/javascript":"\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_formatted_code = \"%load_ext autoreload\\n%autoreload 2\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        nbb_cells[i].set_text(nbb_formatted_code);\n                        break;\n                    }\n                }\n            }, 500);\n            ","text/plain":"<IPython.core.display.Javascript object>"},"metadata":{},"output_type":"display_data"}],"source":"%load_ext autoreload\n%autoreload 2"},{"cell_type":"markdown","metadata":{},"source":["#### Feature selection and engineering pipeline "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"application/javascript":"\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\nimport os\\n\\nfrom src.utils import data_path, split_features_target\\n\\n\\nfrom sklearn.impute import SimpleImputer\\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\n\\n# Continous features\\nCONTINUOUS_FEATURES = [\\\"displacement\\\", \\\"horsepower\\\", \\\"weight\\\", \\\"acceleration\\\"]\\n# Categorical features\\nORDINAL_FEATURES = [\\\"cylinders\\\", \\\"year\\\"]\\nNOMINAL_FEATURES = [\\\"region\\\"]\\n\\n\\ndef make_final_transformation_pipe():\\n\\n    # Build transformation pipelines adapted to feature types\\n    cont_pipeline = Pipeline(\\n        [\\n            (\\\"imputer_cont\\\", SimpleImputer(strategy=\\\"median\\\")),\\n            (\\\"std_scaler_cont\\\", StandardScaler()),\\n        ]\\n    )\\n\\n    ord_pipeline = Pipeline(\\n        [\\n            (\\\"imputer_ord\\\", SimpleImputer(strategy=\\\"most_frequent\\\")),\\n            (\\\"std_scaler_ord\\\", StandardScaler()),\\n        ]\\n    )\\n\\n    full_pipeline = ColumnTransformer(\\n        [\\n            (\\\"cont\\\", cont_pipeline, CONTINUOUS_FEATURES),\\n            (\\\"ord\\\", ord_pipeline, ORDINAL_FEATURES),\\n            (\\\"nom\\\", OneHotEncoder(), NOMINAL_FEATURES),\\n        ]\\n    )\\n\\n    return full_pipeline\\n\\n\\ndef get_interim_data(dataset):\\n    if dataset not in [\\\"train\\\", \\\"test\\\"]:\\n        raise Exception(\\\"dataset type argument is train or test)\\\")\\n    filename = f\\\"{dataset}_cleaned.pkl\\\"\\n    filepath = data_path(\\\"interim\\\", filename)\\n    return pd.read_pickle(filepath)\\n\\n\\ndef make_final_sets():\\n    df_train = get_interim_data(\\\"train\\\")\\n    df_test = get_interim_data(\\\"test\\\")\\n    X_train, y_train = split_features_target(df_train, \\\"mpg\\\")\\n    X_test, y_test = split_features_target(df_test, \\\"mpg\\\")\\n\\n    full_pipeline = make_final_transformation_pipe()\\n    X_train_processed_values = full_pipeline.fit_transform(X_train)\\n    X_test_processed_values = full_pipeline.transform(X_test)\\n    # Add columns names to build the processed dataframe\\n    region_ohe_features = list(\\n        full_pipeline.named_transformers_[\\\"nom\\\"].get_feature_names()\\n    )\\n    column_names = CONTINUOUS_FEATURES + ORDINAL_FEATURES + region_ohe_features\\n    X_train_processed = pd.DataFrame(X_train_processed_values, columns=column_names)\\n    X_test_processed = pd.DataFrame(X_test_processed_values, columns=column_names)\\n\\n    # Drop one of the ohe features to limit correlations in the data set\\n    for df in (X_train_processed, X_test_processed):\\n        df.drop(\\\"x0_EUROPE\\\", axis=1, inplace=True)\\n\\n    # Save the data\\n    df_train_processed = X_train_processed.join(y_train)\\n    df_train_processed.to_csv(data_path(\\\"processed\\\", \\\"train_processed.pkl\\\"))\\n\\n    df_test_processsed = X_test_processed.join(y_test)\\n    df_test_processsed.to_csv(data_path(\\\"processed\\\", \\\"test_processed.pkl\\\"))\\n\\n    return df_train_processed, df_test_processsed\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        nbb_cells[i].set_text(nbb_formatted_code);\n                        break;\n                    }\n                }\n            }, 500);\n            ","text/plain":"<IPython.core.display.Javascript object>"},"metadata":{},"output_type":"display_data"}],"source":"import pandas as pd\nimport numpy as np\nimport os\n\nfrom src.utils import data_path, split_features_target\n\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\n# Continous features\nCONTINUOUS_FEATURES = [\"displacement\", \"horsepower\", \"weight\", \"acceleration\"]\n# Categorical features\nORDINAL_FEATURES = [\"cylinders\", \"year\"]\nNOMINAL_FEATURES = [\"region\"]\n\n\ndef make_final_transformation_pipe():\n\n    # Build transformation pipelines adapted to feature types\n    cont_pipeline = Pipeline(\n        [\n            (\"imputer_cont\", SimpleImputer(strategy=\"median\")),\n            (\"std_scaler_cont\", StandardScaler()),\n        ]\n    )\n\n    ord_pipeline = Pipeline(\n        [\n            (\"imputer_ord\", SimpleImputer(strategy=\"most_frequent\")),\n            (\"std_scaler_ord\", StandardScaler()),\n        ]\n    )\n\n    full_pipeline = ColumnTransformer(\n        [\n            (\"cont\", cont_pipeline, CONTINUOUS_FEATURES),\n            (\"ord\", ord_pipeline, ORDINAL_FEATURES),\n            (\"nom\", OneHotEncoder(), NOMINAL_FEATURES),\n        ]\n    )\n\n    return full_pipeline\n\n\ndef get_interim_data(dataset):\n    if dataset not in [\"train\", \"test\"]:\n        raise Exception(\"dataset type argument is train or test)\")\n    filename = f\"{dataset}_cleaned.pkl\"\n    filepath = data_path(\"interim\", filename)\n    return pd.read_pickle(filepath)\n\n\ndef make_final_sets():\n    df_train = get_interim_data(\"train\")\n    df_test = get_interim_data(\"test\")\n    X_train, y_train = split_features_target(df_train, \"mpg\")\n    X_test, y_test = split_features_target(df_test, \"mpg\")\n\n    full_pipeline = make_final_transformation_pipe()\n    X_train_processed_values = full_pipeline.fit_transform(X_train)\n    X_test_processed_values = full_pipeline.transform(X_test)\n    # Add columns names to build the processed dataframe\n    region_ohe_features = list(\n        full_pipeline.named_transformers_[\"nom\"].get_feature_names()\n    )\n    column_names = CONTINUOUS_FEATURES + ORDINAL_FEATURES + region_ohe_features\n    X_train_processed = pd.DataFrame(X_train_processed_values, columns=column_names)\n    X_test_processed = pd.DataFrame(X_test_processed_values, columns=column_names)\n\n    # Drop one of the ohe features to limit correlations in the data set\n    for df in (X_train_processed, X_test_processed):\n        df.drop(\"x0_EUROPE\", axis=1, inplace=True)\n\n    # Save the data\n    df_train_processed = X_train_processed.join(y_train)\n    df_train_processed.to_csv(data_path(\"processed\", \"train_processed.pkl\"))\n\n    df_test_processsed = X_test_processed.join(y_test)\n    df_test_processsed.to_csv(data_path(\"processed\", \"test_processed.pkl\"))\n\n    return df_train_processed, df_test_processsed"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"/Users/Corentin/Documents/ml_projects/auto-mpg/src\n/Users/Corentin/Documents/ml_projects/auto-mpg/src\n/Users/Corentin/Documents/ml_projects/auto-mpg/src\n/Users/Corentin/Documents/ml_projects/auto-mpg/src\n/Users/Corentin/miniconda3/envs/auto-mpg/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n  warnings.warn(msg, DataConversionWarning)\n/Users/Corentin/miniconda3/envs/auto-mpg/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n  warnings.warn(msg, DataConversionWarning)\n/Users/Corentin/miniconda3/envs/auto-mpg/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n  warnings.warn(msg, DataConversionWarning)\n"},{"data":{"application/javascript":"\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_formatted_code = \"df_train, df_test = make_final_sets()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        nbb_cells[i].set_text(nbb_formatted_code);\n                        break;\n                    }\n                }\n            }, 500);\n            ","text/plain":"<IPython.core.display.Javascript object>"},"metadata":{},"output_type":"display_data"}],"source":"df_train, df_test = make_final_sets()"},{"cell_type":"markdown","metadata":{},"source":["We can ignore this warning. It is expected that Standardizing ordinal features converted them to float. "]},{"cell_type":"markdown","metadata":{},"source":["#### Check training and test sets "]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>displacement</th>\n","      <th>horsepower</th>\n","      <th>weight</th>\n","      <th>acceleration</th>\n","      <th>cylinders</th>\n","      <th>year</th>\n","      <th>x0_ASIA</th>\n","      <th>x0_USA</th>\n","      <th>mpg</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>1.090196</td>\n","      <td>1.266232</td>\n","      <td>0.552826</td>\n","      <td>-1.319334</td>\n","      <td>1.527188</td>\n","      <td>-1.696667</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>-0.922996</td>\n","      <td>-0.407925</td>\n","      <td>-0.999667</td>\n","      <td>-0.413182</td>\n","      <td>-0.850515</td>\n","      <td>-1.696667</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>15.0</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>-0.981350</td>\n","      <td>-0.947975</td>\n","      <td>-1.124772</td>\n","      <td>0.927922</td>\n","      <td>-0.850515</td>\n","      <td>1.638975</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>18.0</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>-0.981350</td>\n","      <td>-1.163996</td>\n","      <td>-1.392854</td>\n","      <td>0.275493</td>\n","      <td>-0.850515</td>\n","      <td>0.527094</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>16.0</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>-0.747936</td>\n","      <td>-0.218907</td>\n","      <td>-0.327675</td>\n","      <td>-0.231952</td>\n","      <td>-0.850515</td>\n","      <td>-0.306816</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>17.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   displacement  horsepower    weight  acceleration  cylinders      year  \\\n","0      1.090196    1.266232  0.552826     -1.319334   1.527188 -1.696667   \n","1     -0.922996   -0.407925 -0.999667     -0.413182  -0.850515 -1.696667   \n","2     -0.981350   -0.947975 -1.124772      0.927922  -0.850515  1.638975   \n","3     -0.981350   -1.163996 -1.392854      0.275493  -0.850515  0.527094   \n","4     -0.747936   -0.218907 -0.327675     -0.231952  -0.850515 -0.306816   \n","\n","   x0_ASIA  x0_USA   mpg  \n","0      0.0     1.0   NaN  \n","1      1.0     0.0  15.0  \n","2      1.0     0.0  18.0  \n","3      1.0     0.0  16.0  \n","4      0.0     0.0  17.0  "]},"execution_count":33,"metadata":{},"output_type":"execute_result"},{"data":{"application/javascript":["\n","            setTimeout(function() {\n","                var nbb_cell_id = 33;\n","                var nbb_formatted_code = \"df_train.head()\";\n","                var nbb_cells = Jupyter.notebook.get_cells();\n","                for (var i = 0; i < nbb_cells.length; ++i) {\n","                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n","                        nbb_cells[i].set_text(nbb_formatted_code);\n","                        break;\n","                    }\n","                }\n","            }, 500);\n","            "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["df_train.head()"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["(318, 9)"]},"execution_count":35,"metadata":{},"output_type":"execute_result"},{"data":{"application/javascript":["\n","            setTimeout(function() {\n","                var nbb_cell_id = 35;\n","                var nbb_formatted_code = \"df_train.shape\";\n","                var nbb_cells = Jupyter.notebook.get_cells();\n","                for (var i = 0; i < nbb_cells.length; ++i) {\n","                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n","                        nbb_cells[i].set_text(nbb_formatted_code);\n","                        break;\n","                    }\n","                }\n","            }, 500);\n","            "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["df_train.shape"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>displacement</th>\n","      <th>horsepower</th>\n","      <th>weight</th>\n","      <th>acceleration</th>\n","      <th>cylinders</th>\n","      <th>year</th>\n","      <th>x0_ASIA</th>\n","      <th>x0_USA</th>\n","      <th>mpg</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>-0.981350</td>\n","      <td>-1.353013</td>\n","      <td>-1.398812</td>\n","      <td>0.637953</td>\n","      <td>-0.850515</td>\n","      <td>-0.028846</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>18.0</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>-0.699308</td>\n","      <td>-0.650948</td>\n","      <td>-0.409887</td>\n","      <td>1.072906</td>\n","      <td>-0.850515</td>\n","      <td>1.638975</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.389956</td>\n","      <td>-0.083895</td>\n","      <td>-0.399163</td>\n","      <td>-0.956873</td>\n","      <td>0.338337</td>\n","      <td>-1.418697</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.226354</td>\n","      <td>1.266232</td>\n","      <td>1.156905</td>\n","      <td>-0.884381</td>\n","      <td>1.527188</td>\n","      <td>-0.028846</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.226354</td>\n","      <td>1.266232</td>\n","      <td>1.510773</td>\n","      <td>-0.413182</td>\n","      <td>1.527188</td>\n","      <td>-0.862757</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   displacement  horsepower    weight  acceleration  cylinders      year  \\\n","0     -0.981350   -1.353013 -1.398812      0.637953  -0.850515 -0.028846   \n","1     -0.699308   -0.650948 -0.409887      1.072906  -0.850515  1.638975   \n","2      0.389956   -0.083895 -0.399163     -0.956873   0.338337 -1.418697   \n","3      1.226354    1.266232  1.156905     -0.884381   1.527188 -0.028846   \n","4      1.226354    1.266232  1.510773     -0.413182   1.527188 -0.862757   \n","\n","   x0_ASIA  x0_USA   mpg  \n","0      1.0     0.0  18.0  \n","1      0.0     1.0   NaN  \n","2      0.0     1.0   NaN  \n","3      0.0     1.0   NaN  \n","4      0.0     1.0   NaN  "]},"execution_count":36,"metadata":{},"output_type":"execute_result"},{"data":{"application/javascript":["\n","            setTimeout(function() {\n","                var nbb_cell_id = 36;\n","                var nbb_formatted_code = \"df_test.head()\";\n","                var nbb_cells = Jupyter.notebook.get_cells();\n","                for (var i = 0; i < nbb_cells.length; ++i) {\n","                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n","                        nbb_cells[i].set_text(nbb_formatted_code);\n","                        break;\n","                    }\n","                }\n","            }, 500);\n","            "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["df_test.head()"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["(80, 9)"]},"execution_count":37,"metadata":{},"output_type":"execute_result"},{"data":{"application/javascript":["\n","            setTimeout(function() {\n","                var nbb_cell_id = 37;\n","                var nbb_formatted_code = \"df_test.shape\";\n","                var nbb_cells = Jupyter.notebook.get_cells();\n","                for (var i = 0; i < nbb_cells.length; ++i) {\n","                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n","                        nbb_cells[i].set_text(nbb_formatted_code);\n","                        break;\n","                    }\n","                }\n","            }, 500);\n","            "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["df_test.shape"]},{"cell_type":"markdown","metadata":{},"source":["Next, we move this code to the module `feature_engineering.py` in the source folder.  "]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}